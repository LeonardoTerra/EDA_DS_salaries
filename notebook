{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5392837,"sourceType":"datasetVersion","datasetId":3125926}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/leonardoterra/eda-ds-jobs?scriptVersionId=181351213\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"**Dataset**\n--\n\n# **DS Salary Dataset**\n    DS Analysis\n    \n## Data Description\nThis analysis is based on a dataset extracted from Kaggle.com. This dataset presents data collected across a period of 4 years to give us more information as types of work, annual salaries, nacionality and else regarding careers in data analysis.\nThe goal of this analysis is to evaluate the collected data to gain more knowledge about this growing field around the world. This is a simple but effective analysis, capable of extracting some statistic infomation with precision.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-03T22:32:08.581968Z","iopub.execute_input":"2024-06-03T22:32:08.582491Z","iopub.status.idle":"2024-06-03T22:32:08.605319Z","shell.execute_reply.started":"2024-06-03T22:32:08.582452Z","shell.execute_reply":"2024-06-03T22:32:08.603857Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"/kaggle/input/data-science-salaries-2023/ds_salaries.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Import Libraries**\n---------","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\n\nwarnings.filterwarnings(\"ignore\") # ou warnings.filterwarnings(\"action='once'\")","metadata":{"execution":{"iopub.status.busy":"2024-06-03T22:32:08.607648Z","iopub.execute_input":"2024-06-03T22:32:08.608398Z","iopub.status.idle":"2024-06-03T22:32:08.628757Z","shell.execute_reply.started":"2024-06-03T22:32:08.608352Z","shell.execute_reply":"2024-06-03T22:32:08.627527Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## **Organizing Dataset**\n---------","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/data-science-salaries-2023/ds_salaries.csv')\ndataset.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T22:32:08.630494Z","iopub.execute_input":"2024-06-03T22:32:08.63118Z","iopub.status.idle":"2024-06-03T22:32:08.663366Z","shell.execute_reply.started":"2024-06-03T22:32:08.631137Z","shell.execute_reply":"2024-06-03T22:32:08.662124Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"   work_year experience_level employment_type                 job_title  \\\n0       2023               SE              FT  Principal Data Scientist   \n1       2023               MI              CT               ML Engineer   \n2       2023               MI              CT               ML Engineer   \n3       2023               SE              FT            Data Scientist   \n4       2023               SE              FT            Data Scientist   \n5       2023               SE              FT         Applied Scientist   \n6       2023               SE              FT         Applied Scientist   \n7       2023               SE              FT            Data Scientist   \n8       2023               SE              FT            Data Scientist   \n9       2023               SE              FT            Data Scientist   \n\n   salary salary_currency  salary_in_usd employee_residence  remote_ratio  \\\n0   80000             EUR          85847                 ES           100   \n1   30000             USD          30000                 US           100   \n2   25500             USD          25500                 US           100   \n3  175000             USD         175000                 CA           100   \n4  120000             USD         120000                 CA           100   \n5  222200             USD         222200                 US             0   \n6  136000             USD         136000                 US             0   \n7  219000             USD         219000                 CA             0   \n8  141000             USD         141000                 CA             0   \n9  147100             USD         147100                 US             0   \n\n  company_location company_size  \n0               ES            L  \n1               US            S  \n2               US            S  \n3               CA            M  \n4               CA            M  \n5               US            L  \n6               US            L  \n7               CA            M  \n8               CA            M  \n9               US            M  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>work_year</th>\n      <th>experience_level</th>\n      <th>employment_type</th>\n      <th>job_title</th>\n      <th>salary</th>\n      <th>salary_currency</th>\n      <th>salary_in_usd</th>\n      <th>employee_residence</th>\n      <th>remote_ratio</th>\n      <th>company_location</th>\n      <th>company_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>Principal Data Scientist</td>\n      <td>80000</td>\n      <td>EUR</td>\n      <td>85847</td>\n      <td>ES</td>\n      <td>100</td>\n      <td>ES</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023</td>\n      <td>MI</td>\n      <td>CT</td>\n      <td>ML Engineer</td>\n      <td>30000</td>\n      <td>USD</td>\n      <td>30000</td>\n      <td>US</td>\n      <td>100</td>\n      <td>US</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023</td>\n      <td>MI</td>\n      <td>CT</td>\n      <td>ML Engineer</td>\n      <td>25500</td>\n      <td>USD</td>\n      <td>25500</td>\n      <td>US</td>\n      <td>100</td>\n      <td>US</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>Data Scientist</td>\n      <td>175000</td>\n      <td>USD</td>\n      <td>175000</td>\n      <td>CA</td>\n      <td>100</td>\n      <td>CA</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2023</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>Data Scientist</td>\n      <td>120000</td>\n      <td>USD</td>\n      <td>120000</td>\n      <td>CA</td>\n      <td>100</td>\n      <td>CA</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2023</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>Applied Scientist</td>\n      <td>222200</td>\n      <td>USD</td>\n      <td>222200</td>\n      <td>US</td>\n      <td>0</td>\n      <td>US</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2023</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>Applied Scientist</td>\n      <td>136000</td>\n      <td>USD</td>\n      <td>136000</td>\n      <td>US</td>\n      <td>0</td>\n      <td>US</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2023</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>Data Scientist</td>\n      <td>219000</td>\n      <td>USD</td>\n      <td>219000</td>\n      <td>CA</td>\n      <td>0</td>\n      <td>CA</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2023</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>Data Scientist</td>\n      <td>141000</td>\n      <td>USD</td>\n      <td>141000</td>\n      <td>CA</td>\n      <td>0</td>\n      <td>CA</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2023</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>Data Scientist</td>\n      <td>147100</td>\n      <td>USD</td>\n      <td>147100</td>\n      <td>US</td>\n      <td>0</td>\n      <td>US</td>\n      <td>M</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"    'SE': 'Senior',\n    'EN': 'Entry level',\n    'EX': 'Executive level',\n    'MI': 'Mid/Intermediate level',\n\n    'FL': 'Freelancer',\n    'CT': 'Contractor',\n    'FT' : 'Full-time',\n    'PT' : 'Part-time'\n\n    'S': 'SMALL',\n    'M': 'MEDIUM',\n    'L' : 'LARGE',\n\n    '0': 'On-Site',\n    '50': 'Half-Remote',\n    '100' : 'Full-Remote',","metadata":{"execution":{"iopub.status.busy":"2024-06-03T22:32:08.666322Z","iopub.execute_input":"2024-06-03T22:32:08.667357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column in dataset.columns:\n    num_distinct_values = len(dataset[column].unique())\n    print(f\"{column}: {num_distinct_values} distinct values\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"As we can see above, the data was indeed collected using a range of 4 years, and We have around 93 job titles.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### III | Cleaning the Data","metadata":{}},{"cell_type":"markdown","source":"► Adjust Salary using Inflation data for a better analysis\n\nWe need to adjust the salary data for the analysis to be more effective. We can't compare data from previous years against the closest year in the dataset because it would be incorrect. To do the analysis correctly, we need to adjust the salary in USD according to the inflation rate for each year. This way we can bring the salaries from past years to the present.","metadata":{}},{"cell_type":"code","source":"us_inflation_rates = {2019: 0.0181, 2020: 0.0123, 2021: 0.0470, 2022: 0.065}\nglobal_inflation_rates = {2019: 0.0219, 2020: 0.0192, 2021: 0.0350, 2022: 0.088}\n\ndef adjust_salary(row):\n    year = row['work_year']\n    original_salary = row['salary_in_usd']\n    currency = row['salary_currency']\n\n    if year == 2023:\n        return original_salary\n\n    adjusted_salary = original_salary\n    for y in range(year, 2023):\n        if currency == 'USD':\n            inflation_rate = us_inflation_rates[y]\n        else:\n            inflation_rate = global_inflation_rates[y]\n\n        adjusted_salary *= (1 + inflation_rate)\n    return adjusted_salary\n\n# Apply the function to the dataset\ndataset['adj_salary_usd'] = dataset.apply(adjust_salary, axis=1).round(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"► Removing duplicates\n\nWe remove some duplicated rows we might have in the dataset. Duplicates are now interesting because they can change the overall result of the analysis.","metadata":{}},{"cell_type":"code","source":"duplicate_rows_data = dataset[dataset.duplicated()]\nprint(\"number of duplicate rows: \", duplicate_rows_data.shape)\n\ndataset.drop_duplicates(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"► Removing Outliers\n\nAfter removing the duplicates we need to remove the outliers from the dataset. Outliers are those numbers tha deviate a lot from the average and can also change the results of an analysis.","metadata":{}},{"cell_type":"code","source":"q1 = dataset['adj_salary_usd'].quantile(0.25)\nq3 = dataset['adj_salary_usd'].quantile(0.75)\n\niqr = q3 - q1 \n\nlower_bound = q1 - 1.5 * iqr\nupper_bound = q3 + 1.5 * iqr\n\ndataset_cleaned = dataset[(dataset['adj_salary_usd'] >= lower_bound) & (dataset['adj_salary_usd'] <= upper_bound)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"► Cleaning up Jobs that appear just once\n\nHere I decided to remove those jobs that appear just once. I decided to remove them because there isn't enough data to evaluate them if they show up just once. They can be consided outliers as well.","metadata":{}},{"cell_type":"code","source":"job_count = dataset_cleaned['job_title'].value_counts()\njobs_to_delete = job_count[job_count == 1].index\njobs_to_delete\n\ndataset_cleaned_jobs = dataset_cleaned[~dataset_cleaned['job_title'].isin(jobs_to_delete)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"► Assigning a broader category to the jobs to improve the analysis\n\nBelow we will asign a broater category to the jobs we have in this dataset. It would be impossible to evaluate all remaining jobs as we have more than 50 job titles in this dataset. Placing them under a group makes it easier to see the differences and carry on the analysis.","metadata":{"execution":{"iopub.status.busy":"2024-05-30T18:24:44.913689Z","iopub.execute_input":"2024-05-30T18:24:44.914083Z","iopub.status.idle":"2024-05-30T18:24:44.921341Z","shell.execute_reply.started":"2024-05-30T18:24:44.914053Z","shell.execute_reply":"2024-05-30T18:24:44.919827Z"}}},{"cell_type":"code","source":"def assign_broader_category(job_title):\n    data_engineering = [\"Data Engineer\", \"Data Analyst\", \"Analytics Engineer\", \"BI Data Analyst\", \"Business Data Analyst\", \"BI Developer\", \"BI Analyst\", \"Business Intelligence Engineer\", \"BI Data Engineer\", \"Power BI Developer\"]\n    data_scientist = [\"Principal Data Scientist\",\"Data Scientist\", \"Applied Scientist\", \"Research Scientist\", \"3D Computer Vision Researcher\", \"Deep Learning Researcher\", \"AI/Computer Vision Engineer\"]\n    machine_learning = [\"Machine Learning Engineer\", \"ML Engineer\", \"Lead Machine Learning Engineer\", \"Principal Machine Learning Engineer\"]\n    data_architecture = [\"Data Architect\", \"Big Data Architect\", \"Cloud Data Architect\", \"Principal Data Architect\"]\n    management = [\"Data Science Manager\", \"Director of Data Science\", \"Head of Data Science\", \"Data Scientist Lead\", \"Head of Machine Learning\", \"Manager Data Management\", \"Data Analytics Manager\"]\n    \n    if job_title in data_engineering:\n        return \"Data Engineering\"\n    elif job_title in data_scientist:\n        return \"Data Science\"\n    elif job_title in machine_learning:\n        return \"Machine Learning\"\n    elif job_title in data_architecture:\n        return \"Data Architecture\"\n    elif job_title in management:\n        return \"Management\"\n    else:\n        return \"Other\"\n\n# Apply the function to the 'job_title' column and create a new column 'job_category'\ndataset_cleaned_jobs['job_category'] = dataset_cleaned_jobs['job_title'].apply(assign_broader_category)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe = dataset_cleaned_jobs[['work_year','experience_level','employment_type','job_title','job_category','salary_in_usd','adj_salary_usd','remote_ratio','company_location','company_size']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a grid of subplots (1 row, 2 columns)\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n\n# Plot the first chart on the first subplot using Seaborn\nsns.histplot(dataset['adj_salary_usd'], ax=axes[0], kde=True)\naxes[0].set_title('Before Cleanup')\naxes[0].set_ylabel('',fontsize=14)\n\n# Plot the second chart on the second subplot using Seaborn\nsns.histplot(dataframe['adj_salary_usd'], ax=axes[1], kde=True)\naxes[1].set_title('After Cleanup')\naxes[1].set_ylabel('',fontsize=14)\n\nsns.despine(left=False, right=True, top=True, bottom=False)\n\n# Adjust layout to prevent overlap\nplt.tight_layout()\n\n# Show the plots\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a grid of subplots (1 row, 2 columns)\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n\n# Plot the third chart using Seaborn\nsns.boxplot(y='adj_salary_usd', data =dataset, orient='v', width=0.2, ax=axes[0])\naxes[0].set_title('Boxplot - Before', fontsize=16)\naxes[0].set_ylabel('',fontsize=14)\n\n# Plot the Fourth chart using Seaborn\nsns.boxplot(y='adj_salary_usd', data =dataframe, orient='v', width=0.2, ax=axes[1])\naxes[1].set_title('Boxplot - After', fontsize=16)\naxes[1].set_ylabel('',fontsize=14)\n\nsns.despine(left=False, right=True, top=True, bottom=False)\n\n# Adjust layout to prevent overlap\nplt.tight_layout()\n\n# Show the plots\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above Boxplots analysis show how clean the data is after handling the outliers.","metadata":{}},{"cell_type":"markdown","source":"## EDA analysis\n\n\n### I | Exploring Data","metadata":{}},{"cell_type":"markdown","source":"► Countries with most % of jobs (Including the USA and not)","metadata":{}},{"cell_type":"code","source":"countries = dataframe[\"company_location\"].value_counts(normalize=True).nlargest(5).round(4)*100\ncountries","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The USA counts for 75% of all data in the dataset.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The chart above shows us the Boom in this field from 2021 to 2022, which keeps grouwing in 2023.","metadata":{}},{"cell_type":"code","source":"without_US = dataframe['company_location'] != \"US\"\n\ntop_5 = dataframe['company_location'][without_US].value_counts().nlargest(5)\ntop_5_locations = top_5.index.to_list()\n\nax = sns.catplot(\n    data=dataframe.query('company_location in @top_5_locations'), kind=\"count\",\n    x=\"work_year\", hue=\"company_location\", legend=False,\n    errorbar=\"sd\", height=6, palette=custom_colors, ci=None,\n)\n\nax.figure.set_size_inches(15, 5)\nax.set_titles('Distribuição de Salário', fontsize=16)\nax.set_ylabels(\"\",fontsize=0)\nax.set_xlabels(\"Nº de Profissões por Ano\",fontsize=10)\nax.add_legend(title='Profissão')\nax.despine(left=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we have the same analysis but excluding the USA to show how the other countries are going. All countries show a growth in the field, but the growth in the UK and Canada respectvely is eye catching.","metadata":{}},{"cell_type":"code","source":"custom_colors = ['#0077b6']\n\nax = sns.boxplot(y='adj_salary_usd', x='company_size', data =dataframe, orient='v', width=0.2, \n                 palette=custom_colors, dodge=True)\n\nax.figure.set_size_inches(18, 6)\nax.set_ylabel('Salário Ajustado',fontsize=12)\nax.set_xlabel('Porte da Empresa',fontsize=12)\nsns.despine(left=False, right=True, top=True, bottom=False)\nax","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe.groupby('company_size')['adj_salary_usd'].mean().round(2).sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here is something interesting: According to this data, Medium companies pay slightly more than their Large counterparts. \n    \nMedium companies: $143,759.68\n\nLarge companies: $115,453.08\n\nSmall companies: $82,753.52","metadata":{}},{"cell_type":"markdown","source":"### II | Exploring Data\nRatio Analysis","metadata":{}},{"cell_type":"markdown","source":"► Do people earn more working from Home or in the office?","metadata":{}},{"cell_type":"code","source":"custom_colors = ['#0077b6']\n\nax = sns.boxplot(y='adj_salary_usd', x='remote_ratio', data =dataframe, orient='v', width=0.2, \n                 palette=custom_colors, dodge=True)\n\nax.figure.set_size_inches(18, 6)\nax.set_title('', fontsize=16)\nax.set_ylabel('Salário Ajustado',fontsize=12)\nax.set_xlabel('Remote Ratio',fontsize=12)\nsns.despine(left=False, right=True, top=True, bottom=False)\n\nax","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe.groupby('remote_ratio')['adj_salary_usd'].median().round(2).sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Another interesting insight: People who work in the office and from home are usually paid around the same while people who work in Hybrid jobs receive less money.","metadata":{}},{"cell_type":"code","source":"custom_colors = ['#03045e','#023e8a','#00b4d8','#90e0ef','#caf0f8']\n\ntop_5 = dataframe['company_location'][without_US].value_counts().nlargest(5)\ntop_5_locations = top_5.index.to_list()\n\nax = sns.catplot(data=dataframe.query('company_location in @top_5_locations'), kind=\"count\", \n    x=\"remote_ratio\", hue=\"experience_level\", errorbar=\"sd\", height=6, palette=custom_colors, legend=False, ci=None)\n\nax.figure.set_size_inches(15, 5)\nax.set_ylabels(\"\",fontsize=0)\nax.set_xlabels(\"Ratio\",fontsize=10)\nax.add_legend(title='Experience Level')\nax.despine(left=True)\n\nax","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we compare both in the office (Ratio 0) and from home (Ratio 100): we can see that we have more Entry level (EN) and Seniors (SE) working from home while Mid employees (MI) working in the office.","metadata":{}},{"cell_type":"code","source":"'''\nCreating a new dataframe using groupby\n'''\nexperience_level = dataframe.groupby(['experience_level','remote_ratio'])\nexperience_ratio_salary = experience_level['adj_salary_usd'].median().round(2).reset_index()\n\n'''\nPloting the new Dataframe\n'''\n\ncustom_colors = ['#03045e','#023e8a','#00b4d8','#90e0ef','#caf0f8']\n\nax = sns.catplot(data=experience_ratio_salary, kind=\"bar\", \n    x=\"remote_ratio\", y='adj_salary_usd', hue=\"experience_level\", errorbar=\"sd\", height=6, palette=custom_colors, legend=False, ci=None)\n\nax.figure.set_size_inches(15, 5)\nax.set_ylabels(\"\",fontsize=0)\nax.set_xlabels(\"Ratio\",fontsize=10)\nax.add_legend(title='Experience Level')\nax.despine(left=True)\n\nax","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Average salary range for each level","metadata":{}},{"cell_type":"code","source":"### III | Exploring Data \nJob Analaysis","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"► What jobs pay better? What is the most popular Job today?","metadata":{}},{"cell_type":"code","source":"pivot_table = dataframe.pivot_table(values='adj_salary_usd', index='job_category', columns='work_year', aggfunc='median')\nplt.figure(figsize=(15, 6))\nsns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap=\"YlGnBu\")\nplt.title('Median Salary by Year')\nplt.xlabel('Year')\nplt.ylabel('')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"In the heat map above we compare the evolution of the salary according to each category. As you can see, Management jobs used to pay much more than the other categories, but now it's aligned to Machine Learning and Data Science. Surprisingly, Data Architecture is now the Job that pays the most.","metadata":{}},{"cell_type":"code","source":"custom_colors = ['#03045e','#023e8a','#00b4d8','#90e0ef','#caf0f8','#48cae4','#90e0ef','#ade8f4']\n\nax = sns.catplot(data=dataframe, kind=\"count\", y='work_year', hue=\"job_category\", errorbar=\"sd\", height=6, hue_order=['Data Science','Machine Learning','Data Engineering','Data Architecture','Management','Other'], palette=custom_colors, legend=False, ci=None)\n\nax.figure.set_size_inches(15, 5)\nax.set_ylabels(\"\",fontsize=0)\nax.set_xlabels(\"Number of Jobs\",fontsize=10)\nax.add_legend(title='Experience Level')\nax.despine(left=True)\n\nax","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here you can see the same view from above but in another perspective. If you look at data engeneering you can see that even though it's not the job that has the best salaries, it's the one that has been growing the most alongside Data Science.","metadata":{}},{"cell_type":"code","source":"groupby = dataframe.groupby(by='job_category')['adj_salary_usd'].describe().round(2)\ncategories = groupby.reset_index()\ncat_jobs = categories[['job_category','mean','std']].sort_values(by='mean', ascending=False)\ncat_jobs.rename(columns = {'job_category': \"Category\", 'mean': 'Mean', 'std': 'STD'}, inplace=True)\n\nfor index, row in cat_jobs.iterrows():\n    for column, value in row.items():\n        print(f\"  {column}: {value}\")\n    print()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we can see an overview about each category that shows the Average salary and the Standard Deviation. Now that we can see these measures we can also make some predictions","metadata":{}},{"cell_type":"markdown","source":"### II |Statistics\nDescriptive Analysis","metadata":{}},{"cell_type":"code","source":"from scipy import stats\nfrom scipy.stats import norm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"► What is the probability of earning above the USA average worldwide?","metadata":{}},{"cell_type":"code","source":"job_category_worldwide = dataframe[without_US].groupby(\"job_category\")\njob_category_usa = dataframe.query('company_location == \"US\"')\n\ngroupby_worldwide = dataframe[without_US].groupby(by='job_category')['adj_salary_usd'].describe().round(2)\ngroupby_usa = dataframe.query('company_location == \"US\"').groupby(by='job_category')['adj_salary_usd'].describe().round(2)\n\ncategories_worldwide = groupby_worldwide.reset_index()\nworldwide = categories_worldwide[['job_category', 'mean', 'std']]\ncategories_usa = groupby_usa.reset_index()\nusa = categories_usa[['job_category', 'mean', 'std']].rename(columns = {'mean':'mean (USA)', 'std':'std (USA)'})\ncomparison = pd.merge(worldwide, usa, on = \"job_category\")\n\ncomparison['z'] = (comparison['mean (USA)'] - comparison['mean']) / comparison['std']\ncomparison\ncomparison['Probability'] = (1 - norm.cdf(comparison['z']).round(2))*100\ncomparison\ncomparison[['job_category','mean','mean (USA)','Probability']]\n\nfor index, row in comparison[['job_category','mean','mean (USA)','Probability']].round(2).iterrows():\n    for column, value in row.items():\n        print(f\"  {column}: {value}\")\n    print()\n\nprint(\"Probability of earning a salary that is above the US average\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see below, people have pretty low chances of earning more than the US average for each category. The job with the best score is Data Architecture, where people have 20% chance of finding a job that pays above the US average in other countries.\n\nThis analysis was calculated using the Z-score for Normal Distributions.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}